{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edb501f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np      \n",
    "import pandas as pd   \n",
    "import datetime as dt\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_validate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import tree\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "import gradio as gr\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5982a724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread AnyIO worker thread:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Downloads\\Anaconda\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Downloads\\Anaconda\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"D:\\Downloads\\Anaconda\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 660, in _thread_pool_worker\n",
      "    func, args, future = work_queue.get()\n",
      "TypeError: cannot unpack non-iterable NoneType object\n"
     ]
    }
   ],
   "source": [
    "## load dataset and models\n",
    "raw_df = pd.read_csv('bike_sharing.csv').drop(columns = ['instant'])\n",
    "tree_model = pickle.load(open('rf_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77968465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for maching learning step\n",
    "\n",
    "def unnormalise_data(raw_df):\n",
    "\n",
    "    df = raw_df.copy()\n",
    "    df['temp'] = df['temp'].apply(lambda x: x*(39-(-8)) + (-8))\n",
    "    df['atemp'] = df['atemp'].apply(lambda x: x*(50-(-16)) + (-16))\n",
    "    df['hum'] = df['hum'].apply(lambda x: x*100)\n",
    "    df['windspeed'] = df['windspeed'].apply(lambda x: x*67)\n",
    "    df['yr'] = df['yr'].apply(lambda x: 2012 if x==1 else 2011)\n",
    "    df['dteday_hr'] = pd.to_datetime(df['dteday'] + \"-\" + df['hr'].apply(lambda x: str(x)), format='%Y-%m-%d-%H')\n",
    "    df['dteday'] = pd.to_datetime(df['dteday'], format='%Y-%m-%d')\n",
    "\n",
    "    return df\n",
    "\n",
    "def convert_categorical(old_df):\n",
    "    df = old_df.copy()\n",
    "    \n",
    "    season_list = ['Spring', 'Summer', 'Fall', 'Winter']\n",
    "    season_keys = np.arange(1,5)\n",
    "    season_map = {season_keys[i]: season_list[i] for i in range(len(season_keys))}\n",
    "    df['season'] = df['season'].transform(lambda x: season_map[x])\n",
    "    \n",
    "    weekday_list = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "    weekday_keys = np.arange(0,7)\n",
    "    weekday_map = {weekday_keys[i]: weekday_list[i] for i in range(len(weekday_keys))}\n",
    "    df['weekday'] = df['weekday'].transform(lambda x: weekday_map[x])\n",
    "    \n",
    "\n",
    "    weathersit_map = {\n",
    "    1: 'Clear / Partly Cloudy',    #Clear, Few clouds, Partly cloudy, Partly cloudy'\n",
    "    2: 'Mist / Cloudy',            # 'Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist',\n",
    "    3: 'Light Rain / Light Snow',    #'Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds',\n",
    "    4: 'Heavy Rain / Ice Pallets / Fog' # 'Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog'\n",
    "    }\n",
    "    df['weathersit'] = df['weathersit'].transform(lambda x: weathersit_map[x])\n",
    "    \n",
    "\n",
    "    month_list = ['January', 'February', 'March', 'April', 'May', 'June', 'July', \n",
    "                  'August', 'September', 'October', 'November', 'December']\n",
    "    month_keys = np.arange(1,13)\n",
    "    month_map = {month_keys[i]: month_list[i] for i in range(len(month_keys))}\n",
    "    df['mnth'] = df['mnth'].transform(lambda x: month_map[x])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def data_split(df):\n",
    "    \n",
    "    df['dteday'] = pd.to_datetime(df['dteday'], format='%Y-%m-%d')\n",
    "\n",
    "    train = df[df['dteday'] < '2012-07-01'].drop(columns = ['dteday'])\n",
    "    val = df[(df['dteday'] >= '2012-07-01') & (df['dteday'] < '2012-10-01')].drop(columns = ['dteday'])\n",
    "    test = df[df['dteday'] >= '2012-10-01'].drop(columns = ['dteday'])\n",
    "\n",
    "    y_train = train[['casual', 'registered']].to_numpy()\n",
    "    y_val = val[['casual', 'registered']].to_numpy()\n",
    "    y_test = test[['casual', 'registered']].to_numpy()\n",
    "\n",
    "    X_train = train.drop(columns = ['casual', 'registered'])\n",
    "    X_val = val.drop(columns = ['casual', 'registered'])\n",
    "    X_test = test.drop(columns = ['casual', 'registered'])\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "# function to get lagged variables\n",
    "\n",
    "def get_lag_var(old_df):\n",
    "    df = old_df.copy()\n",
    "    \n",
    "    lagged_variables = ['temp', 'atemp', 'hum', 'windspeed', 'weathersit']\n",
    "    \n",
    "    for var in lagged_variables:\n",
    "        column_name = str(var) + \"_lag\"\n",
    "        df[column_name] = df[var].shift(1)\n",
    "    \n",
    "    df.drop(columns = lagged_variables, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    df.drop(columns = ['cnt'], inplace=True)\n",
    "        \n",
    "    return df    \n",
    "\n",
    "def preprocess_tree(raw_df):\n",
    "    \n",
    "    df = raw_df.copy()\n",
    "    df = unnormalise_data(df).drop(columns = ['dteday_hr'])\n",
    "    df = convert_categorical(df)\n",
    "    df = get_lag_var(df)\n",
    "    df = pd.get_dummies(df, columns=['season', 'yr', 'mnth', 'weekday','weathersit_lag'], drop_first=False)\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = data_split(df)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "X_train_tree, X_val_tree, X_test_tree, y_train_tree, y_val_tree, y_test_tree = preprocess_tree(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "815fe3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get optimal price based on predicted demand\n",
    "\n",
    "def get_pct_chg_demand_casual(pct_chg_price):\n",
    "    pct_chg_demand = -1.5639 * math.atan(pct_chg_price)\n",
    "    return pct_chg_demand\n",
    "\n",
    "def get_pct_chg_demand_registered(pct_chg_price):\n",
    "    pct_chg_demand = -3.4488 * math.atan(pct_chg_price)\n",
    "    return pct_chg_demand\n",
    "\n",
    "def get_optimal_pct_chg_price_casual(pred_demand, supply):\n",
    "    max_revenue_chg = 0\n",
    "    best_pct_chg_price = 0\n",
    "    \n",
    "    if pred_demand > supply:\n",
    "        best_q_demand = supply\n",
    "        \n",
    "    else:\n",
    "        best_q_demand = pred_demand\n",
    "\n",
    "    for pct_chg_price in np.arange(-0.99, 1.01, 0.01):\n",
    "        pct_chg_demand = get_pct_chg_demand_casual(pct_chg_price)\n",
    "        q_demand = (pct_chg_demand + 1) * pred_demand\n",
    "\n",
    "        # If the quantity demanded at the new price point exceeds the current supply or is negative, ignore and \n",
    "        # check next price point\n",
    "        if  q_demand > supply or q_demand < 0:\n",
    "            continue\n",
    "\n",
    "        if pred_demand > supply:        \n",
    "            old_revenue = supply * 1\n",
    "\n",
    "        else:\n",
    "            old_revenue = pred_demand * 1\n",
    "\n",
    "        new_revenue = (1+pct_chg_demand)*pred_demand * (1+pct_chg_price)\n",
    "        revenue_chg = (new_revenue - old_revenue) / old_revenue\n",
    "\n",
    "\n",
    "        if revenue_chg > max_revenue_chg:\n",
    "            max_revenue_chg = revenue_chg\n",
    "            best_pct_chg_price = pct_chg_price\n",
    "            best_q_demand =  (pct_chg_demand + 1) * pred_demand\n",
    "    \n",
    "    return(max_revenue_chg, best_pct_chg_price, round(best_q_demand))\n",
    "\n",
    "def get_optimal_pct_chg_price_registered(pred_demand, supply):\n",
    "    max_revenue_chg = 0\n",
    "    best_pct_chg_price = 0\n",
    "    \n",
    "    if pred_demand > supply:\n",
    "        best_q_demand = supply\n",
    "        \n",
    "    else:\n",
    "        best_q_demand = pred_demand\n",
    "\n",
    "    for pct_chg_price in np.arange(-0.99, 1.01, 0.01):\n",
    "        pct_chg_demand = get_pct_chg_demand_registered(pct_chg_price)\n",
    "        q_demand = (pct_chg_demand + 1) * pred_demand\n",
    "\n",
    "        # If the quantity demanded at the new price point exceeds the current supply or is negative, ignore and \n",
    "        # check next price point\n",
    "        if  q_demand > supply or q_demand < 0:\n",
    "            continue\n",
    "\n",
    "        if pred_demand > supply:        \n",
    "            old_revenue = supply * 1\n",
    "\n",
    "        else:\n",
    "            old_revenue = pred_demand * 1\n",
    "\n",
    "        new_revenue = (1+pct_chg_demand)*pred_demand * (1+pct_chg_price)\n",
    "        revenue_chg = (new_revenue - old_revenue) / old_revenue\n",
    "\n",
    "        if revenue_chg > max_revenue_chg:\n",
    "            max_revenue_chg = revenue_chg\n",
    "            best_pct_chg_price = pct_chg_price\n",
    "            best_q_demand =  (pct_chg_demand + 1) * pred_demand\n",
    "\n",
    "    return(max_revenue_chg, best_pct_chg_price, round(best_q_demand))\n",
    "\n",
    "def get_optimal_price_chg(pred_casual, pred_registered, total_supply):\n",
    "    supply_registered = round(total_supply * (pred_registered/(pred_registered + pred_casual)))\n",
    "    res_registered = get_optimal_pct_chg_price_registered(pred_registered, supply_registered)\n",
    "    \n",
    "    supply_casual = total_supply - supply_registered\n",
    "    res_casual = get_optimal_pct_chg_price_casual(pred_casual, supply_casual)\n",
    "    \n",
    "    return (res_registered, res_casual)\n",
    "\n",
    "fixed_total_supply = 977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b75a5482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.3836618100439465, -0.24999999999999933, 555),\n",
       " (0.04857665441330836, -0.16999999999999926, 284))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_optimal_price_chg(225, 301, fixed_total_supply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6a7003c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7879/\n",
      "Running on public URL: https://31614.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"https://31614.gradio.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x226990ce3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<fastapi.applications.FastAPI at 0x226976980a0>,\n",
       " 'http://127.0.0.1:7879/',\n",
       " 'https://31614.gradio.app')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread AnyIO worker thread:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Downloads\\Anaconda\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Downloads\\Anaconda\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"D:\\Downloads\\Anaconda\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 660, in _thread_pool_worker\n",
      "    func, args, future = work_queue.get()\n",
      "TypeError: cannot unpack non-iterable NoneType object\n",
      "Exception in thread AnyIO worker thread:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Downloads\\Anaconda\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Downloads\\Anaconda\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"D:\\Downloads\\Anaconda\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 660, in _thread_pool_worker\n",
      "    func, args, future = work_queue.get()\n",
      "TypeError: cannot unpack non-iterable NoneType object\n"
     ]
    }
   ],
   "source": [
    "def model_pred(hour, season, year, month, holiday, day_of_week, working_day, previous_weather_situation,\n",
    "               previous_temperature, previous_feeling_temperature, previous_humidity, previous_windspeed):\n",
    "    \n",
    "    # map 'yes' and 'no' back to 0 and 1\n",
    "\n",
    "    holiday_mapped =  1 if holiday is 'Yes' else 0\n",
    "    working_day_mapped = 1 if working_day is 'Yes' else 0\n",
    "\n",
    "    # create dictionary and dataframe of mapping\n",
    "\n",
    "    dict_variable = {'hr': hour,\n",
    "                     'season': season,\n",
    "                     'yr': year,\n",
    "                     'mnth': month,\n",
    "                     'holiday': holiday_mapped,\n",
    "                     'weekday': day_of_week,\n",
    "                     'workingday': working_day_mapped,\n",
    "                     'weathersit_lag': previous_weather_situation,\n",
    "                     'temp_lag': previous_temperature,\n",
    "                     'atemp_lag': previous_feeling_temperature,\n",
    "                     'hum_lag': previous_humidity, \n",
    "                     'windspeed_lag': previous_windspeed}\n",
    "\n",
    "    X_input = pd.DataFrame(dict_variable, index=[0])\n",
    "\n",
    "    # prepare dataframe in right format for prediction\n",
    "\n",
    "    X_input_dummy = pd.get_dummies(X_input, columns=['season', 'yr', 'mnth', 'weekday','weathersit_lag'], drop_first=False)\n",
    "    X_tree_app = X_train_tree.copy()\n",
    "    combined_df = pd.concat([X_tree_app, X_input_dummy]).fillna(0)\n",
    "    X_values = combined_df.iloc[-1:]\n",
    "\n",
    "    # predict using Random Forest\n",
    "    preds = tree_model.predict(X_values)\n",
    "\n",
    "    predicted_casual = round(preds[0][0])\n",
    "    predicted_registered = round(preds[0][1])\n",
    "    \n",
    "    df_return = pd.DataFrame()\n",
    "    \n",
    "    df_return['User Type'] =['Casual', 'Registered']\n",
    "    df_return['Original Demand (Predicted Users)'] = [predicted_casual, predicted_registered]\n",
    "    \n",
    "    # get best optimal price \n",
    "    res_registered, res_casual = get_optimal_price_chg(predicted_casual, predicted_registered, fixed_total_supply)\n",
    "    \n",
    "    casual_revenue, casual_price, casual_best_demand = res_casual\n",
    "    registered_revenue, registered_price, registered_best_demand = res_registered\n",
    "    \n",
    "    df_return['Optimal Change in Price'] = [casual_price, registered_price]\n",
    "    df_return['New Demand (given optimal price)'] = [casual_best_demand, registered_best_demand]\n",
    "    df_return['Percentage Increase in Revenue'] = [casual_revenue, registered_revenue]\n",
    "    \n",
    "    df_return['Optimal Change in Price'] = pd.Series([\"{0:+.2f}%\".format(val * 100) for val in df_return['Optimal Change in Price']], index = df_return.index)\n",
    "    df_return['Percentage Increase in Revenue'] = pd.Series([\"{0:+.2f}%\".format(val * 100) for val in df_return['Percentage Increase in Revenue']], index = df_return.index)\n",
    "    \n",
    "    return df_return\n",
    "\n",
    "iface = gr.Interface(\n",
    "    model_pred,\n",
    "    [\n",
    "        gr.inputs.Slider(0,23,1),\n",
    "        gr.inputs.Radio(['Spring', 'Summer', 'Fall', 'Winter'], type='value'),\n",
    "         gr.inputs.Radio(['2011', '2012'], type='value'),\n",
    "         gr.inputs.Radio(['January', 'February', 'March', 'April', 'May', 'June', 'July', \n",
    "                  'August', 'September', 'October', 'November', 'December'], type='value'),\n",
    "        gr.inputs.Radio([\"Yes\", \"No\"], type=\"value\"),\n",
    "        gr.inputs.Radio(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], type='value'),\n",
    "        gr.inputs.Radio([\"Yes\", \"No\"], type=\"value\"),\n",
    "        gr.inputs.Radio([\"Clear / Partly Cloudy\", \"Mist / Cloudy\", \"Light Rain / Light Snow\", \"Heavy Rain / Ice Pallets / Fog\"], type=\"value\"),\n",
    "        gr.inputs.Slider(-16, 40),\n",
    "        gr.inputs.Slider(-16, 50),\n",
    "        gr.inputs.Slider(0, 100),\n",
    "        gr.inputs.Slider(0, 60),\n",
    "    ],\n",
    "    \"dataframe\",\n",
    "    title = \"Capital Bike Share Dynamic Pricing Model\",\n",
    "    description = \"Input day/time and current hour's weather information to get next hour's predicted demand and optimal pricing strategy\"\n",
    ")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a848a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
